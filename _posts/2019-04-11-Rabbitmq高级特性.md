---
layout: post
title:  RabbitMQ高级特性
date:   2019-04-09 13:18:00 +0800
categories: 中间件
tag: RabbitMQ
---



## RabbitMQ高级特性

### 一、消息如何保障100%投递成功？

#### 什么是生产端的可靠性投递

1. 保障消息的成功发出

2. 保障MQ节点的成功接受

3. 发送端收到MQ节点（Broker）确认应答

   生产者生产一条消息，成功的发送了出去，Broker也接收到了消息，也进行存储了，MQ节点需要给生产者端回送一个应答，告诉它消息我已经收到了

4. 完善的消息补偿机制

   如果想保证100%投递成功，仅仅做到前面3步时不够的，有时候有一些极端的临界值的状态，生产端在投递消息的时候就失败了，没有收到任何结果，或者生产者投递到了MQ，MQ也收到了，在返回确认应答的时候，此时突然发生网络闪断，导致生产端没有收到应答，此时生产端就不知道有没有投递成功







#### BAT/TMD互联网大厂的解决方案：

1. 消息落库，对消息进行打标

   即在发送消息的时候，要把消息持久化到数据库里，然后在消息上设置一个状态，比如刚发送出去时是发送中（state=0），到达服务端，服务端收到响应一个应答，此时将数据库里的消息状态做一个变更(state=1)。对于一些没有相应的消息的消息状态的，需要一个轮询操作，去轮询抓取处于不OK的消息，然后重新发送，做最大努力尝试次数，然后循环上述操作，什么时候消息将状态修改了，那么就认为此消息发送成功了

   ![]({{ '/styles/images/mq/可靠性投递.PNG' | prepend: site.baseurl }})

   step1插入失败可以快速失败。

   Step3失败时，如果超过超时时间，MSG DB应该把消息状态仍未改变的数据抽取出来，即用分布式定时任务定时抓取

   

2. 消息的延迟投递，做二次确认，回调检测（减少数据库操作）
   ![]({{ '/styles/images/mq/消息投递.PNG' | prepend: site.baseurl }})
   这种架构只有一次数据库操作，消息的发送一定是在数据库插入之后
   发完一条消息，延迟一会，再发一条消息
   一二步成功后，消费端处理完成之后，会发送一个确认消息（把处理成功这件事生成一条消息投递到mq）
   Callback Service监听到此消息就知道下游服务已经成功了，然后Callback Service就将消息落库
   Callback Service也监听了另外一个延迟消息队列，然后检查MSG DB，发现下游已经处理好了，然后就不需要做任何事情了
   如果下游没有返回或者消费失败，或者更新数据库时失败，此时Callback Service就要做补偿。此时Callback Service发起一个RPC通信，告诉上游服务，刚才消息发送失败。此时会发送一条ReSend Command（携带一个id）告诉需要上游resend刚才的消息。此时UpStream会主动查询一下BIZ DB，再把这条消息重新发送出去，再走一系列的上述流程。这是互联网大厂的一种主流方案。此方案的目的时为了少一次DB的存储。
   这种方案还做到了消息入库与核心链路相分离








### 幂等性概念

无论多少次操作，与只有一次的操作结果是一样的。类似mysql中的读已提交。



### 在海量订单产生的业务高峰器如何避免消息的重复消费问题？

消费端实现幂等性，就意味着，我们的消息永远不会消费多次，即使我们收到了多条一样的消息。

互联网金融行业，涉及到钱，幂等性要求比较严格

#### 业界主流的幂等性操作：

1. ##### 唯一ID+指纹码（https://github.com/rabbitmq/erlang-rpm安装erlang时好像有看到指纹码），利用数据库去重

2. ##### 利用Redis的原子性操作去实现

##### 唯一ID+指纹码

- ###### 唯一ID+指纹码机制，利用数据库主键去重。

为什么要有指纹码，有可能就是某一个用户某一瞬间进行了几次消费。比如一开始转了一些钱，紧接着又转了一些钱，指纹码有可能是根据业务规则和时间戳加上具体的银行生成的一个唯一信息码，并不一定是系统生成的，而是根据一些外部的规则或者内部的业务规则拼接起来的一个标识，目的就是保障这次操作是绝对唯一的。

- ###### SELECT COUNT(1) FROM T_ORDER WHERE ID = 唯一ID+指纹码

  如果没有就插入，如果返回结果为1，返回失败

- ###### 好处：实现简单

- ###### 坏处：高并发下有数据库写入的性能瓶颈

- ###### 解决方案：跟进ID进行分库分表进行算法路由，分摊数据库压力

  

##### 利用Redis的原子性操作去实现

###### 使用Redis进行幂等，需要考虑的问题。

第一，是否要进行数据落库，如果落库的话，关键解决的问题是数据库和缓存如何做到原子性？

有可能redis成功了，数据库插入失败了，怎么处理？

第二，如果不进行落库，那么都存储到缓存中，如何设置定时同步的策略？

缓存上的数据肯定要持久化，这才是最稳妥的。另外一个问题就是放在缓存中一定100%成功吗？

缓存出问题了怎么处理？

set一个key，第二次再set会把这个值更新成最新的，也可以用exist先进行判断存不存在，如果存在就不更新了

或者用redis自带的自增，也能保障原子性



### Confirm确认消息、Return返回消息

#### confirm消息确认机制：

- 消息确认，是指生产者投递消息后，如果broker收到消息，则会给生产者一个应答。

- 生产者进行接收应答，用来确认这条消息是否正常的发送到Broker，这种方式也是消息的可靠性投递的核心保障。



#### 如何实现Confirm确认消息？

第一步：在channel上开启确认模式：channel.confirmSelect()

第二步：在channel上添加监听：addConfirmListener，监听成功和失败的返回结果，根据具体的结果对消息进行重新发送、或记录日志等待后续处理

##### 消费者

```java
import com.rabbitmq.client.*;

import java.io.IOException;

public class Consumer {

    public static void main(String[] args) throws Exception {
        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.0.132");
        connectionFactory.setPort(5672);
        connectionFactory.setVirtualHost("/");

        Connection connection = connectionFactory.newConnection();

        Channel channel = connection.createChannel();

        String exchangeName = "test_confirm_exchange";
        String routingKey = "confirm.#";
        String queueName = "test_confirm_queue";


        channel.exchangeDeclare(exchangeName, "topic", true);
        channel.queueDeclare(queueName, true, false, false, null);

        channel.queueBind(queueName, exchangeName, routingKey);

        DefaultConsumer consumer = new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                String routingKey = envelope.getRoutingKey();
                String contentType = properties.getContentType();
                long deliveryTag = envelope.getDeliveryTag();
                System.out.println(new String(body));
            }
        };

        channel.basicConsume(queueName,true,consumer);

    }
}
```

##### 生产者

```java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.ConfirmListener;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

import java.io.IOException;

public class Producer {

    public static void main(String[] args) throws Exception {

        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.0.132");
        connectionFactory.setPort(5672);
        connectionFactory.setVirtualHost("/");

        Connection connection = connectionFactory.newConnection();

        Channel channel = connection.createChannel();

        channel.confirmSelect();

        String exchangeName = "test_confirm_exchange";
        String routingKey = "confirm.save";
        String msg = "Hello RabbitMQ send confirm message";
        channel.basicPublish(exchangeName, routingKey, null, msg.getBytes());

        //网络闪断，两个都收不到
        channel.addConfirmListener(new ConfirmListener() {
            @Override
            public void handleAck(long deliveryTag, boolean multiple) throws IOException {
                System.out.println("------------ack!------------");
            }

            /**
             * 如果磁盘写满了，或者mq出现了异常，或者queue容量到达了上限
             */
            @Override
            public void handleNack(long deliveryTag, boolean multiple) throws IOException {
                System.err.println("---------no ack!-----------");
            }
        });

    }
}
```



#### Return消息机制

- Return Listener用于处理一些不可路由的消息！
- 我们的消息生产者，通过指定一个Exchange和RoutingKey，把消息送达到某一个队列中去，然后我们的消费者监听队列，进行消费处理操作
- 在某些情况下，如果我们在发送消息的时候，当前的exchange不存在或者指定的路由key路由不到，这个时候我们需要监听这种不可达的消息，就要使用Return Listener！
- 关键配置项：Mandatory：如果为true，则监听器会接收到路由不可达的消息，然后进行后续处理，如果未false，那么broker端自动删除该消息！



### 自定义消费者

```java
public class MyConsumer extends DefaultConsumer {

    public MyConsumer(Channel channel) {
        super(channel);
    }


    @Override
    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
        String routingKey = envelope.getRoutingKey();
        String contentType = properties.getContentType();
        long deliveryTag = envelope.getDeliveryTag();
        System.out.println("-------------------consume message-------------------");
        System.out.println("consumerTag:" + consumerTag);
        System.out.println("envelope:" + envelope);
        System.out.println("properties:" + properties);
        System.out.println(new String(body));
    }
}
```





### 消息的ACK与重回队列

#### 消费端的手工ACK和NACK

- 消费端进行消费的时候，如果由于业务异常我们可以进行日志的记录，然后进行补偿！
- 如果由于服务器宕机等严重问题，那我们就需要手工进行ACK保证消费端消费成功！

#### 消费端的重回队列

- 消费端重回队列是为了对没有处理成功的消息，把消息重新投递给Broker
- 一般在实际应用中，都会关闭重回队列，也就是设置为false





### 消息限流

#### 什么是消费端的限流？

假设RabbitMQ服务器上有上万条未处理的消息，我们随便打开一个消费者客户端，会出现下列情况：

巨量的消息瞬间团部推送过来，但是我们当客户端无法同时处理这么多数据！很有可能导致服务崩溃，导致严重的生产事故！

RabbitMQ提供了一种qos（服务质量保证）功能，即在**非自动确认**消息的前提下，如果一定数目的消息（通过基于consume或者channel设置Qos的值）未被确认钱，不进行消费新的消息。

```java
basicQos(int prefetchSize, int prefetchCount, boolean global)
```

prefetchSize：0，不限制

prefetchCount：会告诉RabbitMQ不用同时给一个消费者推送多于N个消息，即一旦有N个消息还没有ack，则该consume将block掉，直到有消息ack

global：true\false是否将上面设置应用于channel，即上面限制是channel级别还是consumer级别

prefecthSize和global这两项，RabbitMQ没有实现

prefetchCount在no_ack=false的情况下生效，即在自动应答的情况下这两个值是不生效的。

##### 消费者

```java
import com.rabbitmq.client.*;

import java.io.IOException;

public class Consumer {

    public static void main(String[] args) throws Exception {
        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.0.132");
        connectionFactory.setPort(5672);
        connectionFactory.setVirtualHost("/");

        Connection connection = connectionFactory.newConnection();

        Channel channel = connection.createChannel();

        channel.confirmSelect();

        String exchangeName = "test_qos_exchange";
        String routingKey = "qos.#";
        String queueName = "test_qos_queue";


        channel.exchangeDeclare(exchangeName, "topic", true, false, null);
        channel.queueDeclare(queueName, true, false, false, null);

        channel.queueBind(queueName, exchangeName, routingKey);

        channel.basicQos(0, 1, false);

        channel.basicConsume(queueName, false, new MyConsumer(channel));

    }
}
```

##### 生产者

```java
import com.rabbitmq.client.*;

import java.io.IOException;

public class Producer {

    public static void main(String[] args) throws Exception {

        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.0.132");
        connectionFactory.setPort(5672);
        connectionFactory.setVirtualHost("/");

        Connection connection = connectionFactory.newConnection();

        Channel channel = connection.createChannel();

        channel.confirmSelect();
        String exchangeName = "test_qos_exchange";
        String routingKey = "qos.save";
        String msg = "Hello RabbitMQ send qos message";

        for (int i = 0; i < 5; i++) {
            channel.basicPublish(exchangeName, routingKey, true, null, msg.getBytes());
        }



    }
}
```

##### 自定义消费者

```java
import com.rabbitmq.client.AMQP;
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.DefaultConsumer;
import com.rabbitmq.client.Envelope;

import java.io.IOException;

public class MyConsumer extends DefaultConsumer {

    public MyConsumer(Channel channel) {
        super(channel);
    }


    @Override
    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
        long deliveryTag = envelope.getDeliveryTag();
        System.out.println("-------------------consume message-------------------");
        System.out.println("consumerTag:" + consumerTag);
        System.out.println("envelope:" + envelope);
        System.out.println("properties:" + properties);
        System.out.println(new String(body));

        Channel channel = getChannel();
        channel.basicAck(deliveryTag, false);

    }
}
```



### TTL消息

Time To Live的缩写，也就是生存时间

RabbitMQ支持消息的过期时间，在消息发送时可以进行指定

RabbitMQ支持队列的过期时间，从消息入队列开始计算，只要超过了队列的超时时间，那么消息会自动的清除



两种方式：

一种是给某一条消息设置ttl，过期删除此条消息

另一种是给队列设置ttl，该队列里的消息到达过期时间就会被删除

### 死信队列

##### 死信队列：DLX，Dead-Letter-Exchange

##### 死信：没有任何消费者消费的消息

利用DLX，当消息在一个队列中变成死信（dead message）之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX



#### 消息变成死信队列有以下几种情况

- 消息被拒绝（basic.reject/basic.nack）并且requeue=false
- 消息ttl过期
- 队列达到最大长度

DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。

当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列。

可以监听这个死信队列中的消息做相应的处理，这个特性可以弥补RabbitMQ3.0以前支持的immediate参数的功能



死信队列设置：

首先需要设置死信队列的exchange和queue，然后进行绑定：

Exchange：dlx.exchange

Queue：dlx.queue

RoutingKey：#

然后声明交换机、队列、绑定，只不过我们需要在队列上加一个参数即可：arguments.put("x-dead-exchange","dlx.exchange")

这样消息在过期、requeue、队列在达到最大长度时，消息就可以直接路由到死信队列！

在实际工作中死信队列很重要，能够让我们更优雅的做一些消息的补偿。



消费者

```java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

import java.util.HashMap;
import java.util.Map;

public class Consumer {

    public static void main(String[] args) throws Exception {
        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.0.132");
        connectionFactory.setPort(5672);
        connectionFactory.setVirtualHost("/");

        Connection connection = connectionFactory.newConnection();

        Channel channel = connection.createChannel();

        channel.confirmSelect();

        String exchangeName = "test_dlx_exchange";
        String routingKey = "dlx.#";
        String queueName = "test_dlx_queue";


        channel.exchangeDeclare(exchangeName, "topic", true, false, null);
        Map<String, Object> arguments = new HashMap<>();
        arguments.put("x-dead-letter-exchange","dlx.exchange");
        channel.queueDeclare(queueName, true, false, false, arguments);
        channel.queueBind(queueName, exchangeName, routingKey);

        channel.exchangeDeclare("dlx.exchange", "topic", true, false, null);
        channel.queueDeclare("dlx.queue", true, false, false, null);
        channel.queueBind("dlx.queue", "dlx.exchange", "#");

        //channel.basicQos(0, 1, false);
        //手工签收
        channel.basicConsume(queueName, false, new MyConsumer(channel));

    }
}
```

生产者

```java
import com.rabbitmq.client.AMQP;
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

import java.util.HashMap;
import java.util.Map;

public class Producer {

    public static void main(String[] args) throws Exception {

        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.0.132");
        connectionFactory.setPort(5672);
        connectionFactory.setVirtualHost("/");

        Connection connection = connectionFactory.newConnection();

        Channel channel = connection.createChannel();

        channel.confirmSelect();

        String exchangeName = "test_dlx_exchange";
        String routingKey = "dlx.save";


        for (int i = 0; i < 5; i++) {
            String msg = "Hello RabbitMQ send dlx " + i + " message";
            Map<String, Object> headers = new HashMap<>();
            headers.put("num", i);

            AMQP.BasicProperties properties = new AMQP.BasicProperties().builder()
                    .deliveryMode(2)//持久化
                    .contentEncoding("UTF-8")
                    .expiration("10000")
                    .headers(headers)
                    .build();
            channel.basicPublish(exchangeName, routingKey, true, properties, msg.getBytes());
        }


    }
}
```

![]({{ '/styles/images/mq/dlx.PNG' | prepend: site.baseurl }})